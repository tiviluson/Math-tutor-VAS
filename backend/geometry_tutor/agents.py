"""
LangGraph node implementations (AI Agents) for the Geometry Tutor system.
"""

import json
from typing import List, Dict

from .core import GraphState, format_facts_list
from .llm_utils import initialize_llm, safe_json_parse


def parse_problem(state: GraphState) -> GraphState:
    """
    Node 1: parse_problem
    Agent: "Parsing Agent"
    Extracts structured information from the Vietnamese geometry problem.
    """
    llm = initialize_llm()
    if not llm:
        state["error_message"] = (
            "KhÃ´ng thá»ƒ khá»Ÿi táº¡o mÃ´ hÃ¬nh AI. Vui lÃ²ng kiá»ƒm tra cáº¥u hÃ¬nh API."
        )
        return state

    parsing_prompt = f"""
Báº¡n lÃ  má»™t chuyÃªn gia hÃ¬nh há»c. HÃ£y Ä‘á»c bÃ i toÃ¡n sau vÃ  trÃ­ch xuáº¥t táº¥t cáº£ thÃ´ng tin hÃ¬nh há»c, 
cÃ¡c sá»± kiá»‡n Ä‘Ã£ cho, cÃ¡c cÃ¢u há»i riÃªng biá»‡t, vÃ  cÃ¡c bÆ°á»›c váº½ hÃ¬nh thÃ nh Ä‘á»‹nh dáº¡ng JSON.

CÃ¡c cÃ¢u há»i pháº£i Ä‘Æ°á»£c sáº¯p xáº¿p theo thá»© tá»± tuáº§n tá»± Ä‘Ãºng.
CÃ¡c cÃ¢u há»i pháº£i Ä‘Æ°á»£c viáº¿t láº¡i chÃ­nh xÃ¡c, khÃ´ng cÃ³ sá»± thay Ä‘á»•i nÃ o so vá»›i Ä‘á» bÃ i.
Cáº£ cÃ¡c sá»± kiá»‡n Ä‘Ã£ cho vÃ  cÃ¢u há»i pháº£i Ä‘Æ°á»£c viáº¿t báº±ng tiáº¿ng Viá»‡t.
CÃ¡c bÆ°á»›c váº½ hÃ¬nh pháº£i Ä‘Æ°á»£c mÃ´ táº£ chi tiáº¿t, rÃµ rÃ ng Ä‘á»ƒ há»c sinh cÃ³ thá»ƒ váº½ láº¡i Ä‘Æ°á»£c.

BÃ i toÃ¡n: {state['original_problem']}

Vui lÃ²ng tráº£ vá» JSON vá»›i Ä‘á»‹nh dáº¡ng sau:
{{
    "points": ["A", "B", "C", ...],
    "lines": ["AB", "BC", ...],
    "shapes": ["triangle ABC", "circle O", ...],
    "given_facts": ["AB = 5", "gÃ³c ABC = 90Â°", ...],
    "questions": ["Chá»©ng minh tam giÃ¡c ABC vuÃ´ng", "TÃ­nh diá»‡n tÃ­ch tam giÃ¡c", ...],
    "illustration_steps": ["Váº½ Ä‘Æ°á»ng trÃ²n tÃ¢m O, bÃ¡n kÃ­nh R", "Láº¥y Ä‘iá»ƒm A trÃªn Ä‘Æ°á»ng tháº³ng qua O", ...]
}}
"""

    try:
        response = llm.invoke(parsing_prompt)
        parsed_data = safe_json_parse(
            response.content,
            {
                "points": [],
                "lines": [],
                "shapes": [],
                "given_facts": [],
                "questions": [],
                "illustration_steps": [],
            },
        )

        state["parsed_elements"] = {
            "points": parsed_data.get("points", []),
            "lines": parsed_data.get("lines", []),
            "shapes": parsed_data.get("shapes", []),
            "facts": parsed_data.get("given_facts", []),
        }

        state["questions"] = parsed_data.get("questions", [])
        state["known_facts"] = parsed_data.get("given_facts", []).copy()

        # Add illustration steps from parsing
        illustration_steps = parsed_data.get("illustration_steps", [])
        state["illustration_steps"].extend(illustration_steps)

        if not state["questions"]:
            state["error_message"] = (
                "KhÃ´ng thá»ƒ phÃ¢n tÃ­ch cÃ¡c cÃ¢u há»i tá»« bÃ i toÃ¡n. Vui lÃ²ng kiá»ƒm tra láº¡i Ä‘á» bÃ i."
            )
        else:
            state["error_message"] = ""

    except Exception as e:
        state["error_message"] = f"Lá»—i khi phÃ¢n tÃ­ch bÃ i toÃ¡n: {str(e)}"

    return state


def reason_and_solve(state: GraphState) -> GraphState:
    """
    Node 2: reason_and_solve
    Agent: "Solver Agent"
    Develops a step-by-step solution for the current question using iterative reasoning.
    AI discoveries are kept separate from user's known facts until solution is validated.
    """
    llm = initialize_llm()
    if not llm:
        state["error_message"] = "KhÃ´ng thá»ƒ khá»Ÿi táº¡o mÃ´ hÃ¬nh AI."
        return state

    if state["current_question_index"] >= len(state["questions"]):
        state["session_complete"] = True
        return state

    current_question = state["questions"][state["current_question_index"]]
    # Use only the base known facts (from problem) + any previously validated AI discoveries
    base_facts = state["known_facts"]
    ai_discoveries = []  # Fresh AI discoveries for this reasoning session
    reasoning_chain = []

    max_iterations = 10  # Prevent infinite loops
    iteration = 0

    while iteration < max_iterations:
        # Combine base facts with current AI discoveries for reasoning
        all_available_facts = base_facts + ai_discoveries

        solver_prompt = f"""
Báº¡n lÃ  má»™t chuyÃªn gia giáº£i toÃ¡n hÃ¬nh há»c. Má»¥c tiÃªu cá»§a báº¡n lÃ  chá»©ng minh/giáº£i quyáº¿t: {current_question}

Báº¡n Ä‘Ã£ biáº¿t cÃ¡c sá»± kiá»‡n sau:
{format_facts_list(all_available_facts)}

BÆ°á»›c láº­p luáº­n Ä‘Ã£ thá»±c hiá»‡n:
{json.dumps(reasoning_chain, ensure_ascii=False, indent=2) if reasoning_chain else "ChÆ°a cÃ³ bÆ°á»›c nÃ o"}

HÃ£y xÃ¡c Ä‘á»‹nh bÆ°á»›c logic tiáº¿p theo Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c má»¥c tiÃªu. Tráº£ vá» JSON vá»›i Ä‘á»‹nh dáº¡ng:
{{
    "thought": "Suy nghÄ© logic cho bÆ°á»›c nÃ y, bao gá»“m láº­p luáº­n chi tiáº¿t",
    "conclusion": "Káº¿t luáº­n cá»¥ thá»ƒ tá»« bÆ°á»›c nÃ y. Chá»‰ bao gá»“m káº¿t luáº­n cuá»‘i cÃ¹ng, khÃ´ng cáº§n láº­p luáº­n",
    "is_goal_reached": true/false
}}

Náº¿u káº¿t luáº­n Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c má»¥c tiÃªu (tráº£ lá»i Ä‘Æ°á»£c cÃ¢u há»i), hÃ£y Ä‘áº·t is_goal_reached = true.
"""

        try:
            response = llm.invoke(solver_prompt)
            step_data = safe_json_parse(
                response.content,
                {
                    "thought": "KhÃ´ng thá»ƒ phÃ¢n tÃ­ch bÆ°á»›c nÃ y",
                    "conclusion": "",
                    "is_goal_reached": False,
                },
            )

            reasoning_chain.append(
                {
                    "thought": step_data.get("thought", ""),
                    "conclusion": step_data.get("conclusion", ""),
                }
            )

            # Add new conclusion to AI discoveries (separate from user's known facts)
            conclusion = step_data.get("conclusion", "").strip()
            if conclusion and conclusion not in all_available_facts:
                ai_discoveries.append(conclusion)

            # Check if goal is reached
            if (
                step_data.get("is_goal_reached", False)
                or iteration >= max_iterations - 1
            ):
                break

        except Exception as e:
            reasoning_chain.append(
                {
                    "thought": f"Lá»—i trong quÃ¡ trÃ¬nh láº­p luáº­n: {str(e)}",
                    "conclusion": "KhÃ´ng thá»ƒ tiáº¿p tá»¥c láº­p luáº­n",
                }
            )
            break

        iteration += 1

    # Store the reasoning chain and AI discoveries separately
    state["reasoning_chain"] = reasoning_chain
    state["ai_discovered_facts"] = ai_discoveries
    # known_facts remains unchanged - only contains original problem facts

    return state


def generate_hint(state: GraphState) -> GraphState:
    """
    Node 3: generate_hint
    Agent: "Hinting Agent"
    Provides scaffolded hints based on the AI's solution path.
    """
    llm = initialize_llm()
    if not llm:
        state["error_message"] = "KhÃ´ng thá»ƒ khá»Ÿi táº¡o mÃ´ hÃ¬nh AI."
        return state

    reasoning_chain = state["reasoning_chain"]
    hint_level = state["hint_level"]
    current_question = state["questions"][state["current_question_index"]]

    if hint_level >= 3:
        state["generated_hints"].append(
            "Báº¡n Ä‘Ã£ sá»­ dá»¥ng háº¿t sá»‘ láº§n gá»£i Ã½. HÃ£y thá»­ giáº£i hoáº·c xem Ä‘Ã¡p Ã¡n."
        )
        return state

    # Increment hint level
    state["hint_level"] = hint_level + 1
    new_hint_level = state["hint_level"]

    if new_hint_level == 1:
        # Hint 1: Conceptual - General strategy
        hint_prompt = f"""
Báº¡n lÃ  má»™t giÃ¡o viÃªn hÃ¬nh há»c. Há»c sinh Ä‘ang giáº£i cÃ¢u há»i: {current_question}

CÃ¡c sá»± kiá»‡n há»c sinh Ä‘Ã£ biáº¿t:
{format_facts_list(state["known_facts"])}

Chuá»—i láº­p luáº­n Ä‘Ãºng lÃ :
{json.dumps(reasoning_chain, ensure_ascii=False, indent=2)}

HÃ£y Ä‘Æ°a ra gá»£i Ã½ khÃ¡i niá»‡m tá»•ng quÃ¡t (khÃ´ng tiáº¿t lá»™ chi tiáº¿t cá»¥ thá»ƒ) vá» chiáº¿n lÆ°á»£c giáº£i quyáº¿t. 
Äáº·t cÃ¢u há»i hÆ°á»›ng dáº«n Ä‘á»ƒ há»c sinh tá»± suy nghÄ©.
"""

    elif new_hint_level == 2:
        # Hint 2: Contextual - Point to specific facts
        # Use only user's known facts for hints, not AI discoveries
        hint_prompt = f"""
Báº¡n lÃ  má»™t giÃ¡o viÃªn hÃ¬nh há»c. Há»c sinh Ä‘ang giáº£i cÃ¢u há»i: {current_question}

CÃ¡c sá»± kiá»‡n há»c sinh Ä‘Ã£ biáº¿t:
{format_facts_list(state["known_facts"])}

Chuá»—i láº­p luáº­n Ä‘Ãºng:
{json.dumps(reasoning_chain, ensure_ascii=False, indent=2)}

HÃ£y chá»‰ ra nhá»¯ng sá»± kiá»‡n cá»¥ thá»ƒ tá»« danh sÃ¡ch Ä‘Ã£ biáº¿t mÃ  há»c sinh cáº§n chÃº Ã½ Ä‘á»ƒ thá»±c hiá»‡n bÆ°á»›c tiáº¿p theo.
KhÃ´ng tiáº¿t lá»™ bÆ°á»›c láº­p luáº­n, chá»‰ hÆ°á»›ng dáº«n táº­p trung vÃ o thÃ´ng tin nÃ o.
"""

    else:  # hint_level == 3
        # Hint 3: Direct - Next step suggestion
        hint_prompt = f"""
Báº¡n lÃ  má»™t giÃ¡o viÃªn hÃ¬nh há»c. Há»c sinh Ä‘ang giáº£i cÃ¢u há»i: {current_question}

CÃ¡c sá»± kiá»‡n há»c sinh Ä‘Ã£ biáº¿t:
{format_facts_list(state["known_facts"])}

Chuá»—i láº­p luáº­n Ä‘Ãºng:
{json.dumps(reasoning_chain, ensure_ascii=False, indent=2)}

HÃ£y gá»£i Ã½ trá»±c tiáº¿p bÆ°á»›c tiáº¿p theo mÃ  há»c sinh nÃªn thá»±c hiá»‡n, nhÆ°ng váº«n Ä‘á»ƒ há»c sinh tá»± hoÃ n thÃ nh.
ÄÆ°a ra má»™t gá»£i Ã½ cá»¥ thá»ƒ dÆ°á»›i dáº¡ng Ä‘á» xuáº¥t.
"""

    try:
        response = llm.invoke(hint_prompt)
        hint_text = response.content.strip()
        state["generated_hints"].append(hint_text)

        # Display the generated hint immediately
        print("\n" + "=" * 60)
        print(f"ðŸ’¡ Gá»¢I Ã Láº¦N {new_hint_level}")
        print("=" * 60)
        print(hint_text)
        print("=" * 60 + "\n")

    except Exception as e:
        error_message = f"Lá»—i khi táº¡o gá»£i Ã½: {str(e)}"
        state["generated_hints"].append(error_message)
        print(f"âŒ {error_message}")

    return state


def validate_solution(state: GraphState) -> GraphState:
    """
    Node 4: validate_solution
    Agent: "Validation Agent"
    Compares student solution with the correct reasoning path.
    """
    llm = initialize_llm()
    if not llm:
        state["error_message"] = "KhÃ´ng thá»ƒ khá»Ÿi táº¡o mÃ´ hÃ¬nh AI."
        return state

    user_solution = state["user_solution_attempt"]
    reasoning_chain = state["reasoning_chain"]
    current_question = state["questions"][state["current_question_index"]]

    validation_prompt = f"""
Báº¡n lÃ  má»™t trá»£ giáº£ng dáº¡y hÃ¬nh há»c. Má»™t chuá»—i láº­p luáº­n Ä‘Ãºng lÃ :

{json.dumps(reasoning_chain, ensure_ascii=False, indent=2)}

Há»c sinh Ä‘Ã£ ná»™p lá»i giáº£i sau cho cÃ¢u há»i "{current_question}":

{user_solution}

HÃ£y so sÃ¡nh láº­p luáº­n cá»§a há»c sinh vá»›i Ä‘Æ°á»ng lá»‘i giáº£i Ä‘Ãºng. Láº­p luáº­n cá»§a há»c sinh cÃ³ há»£p lÃ½ khÃ´ng?

Náº¿u Ä‘Ãºng, hÃ£y khen ngá»£i vÃ  xÃ¡c nháº­n. Náº¿u sai, hÃ£y nháº¹ nhÃ ng giáº£i thÃ­ch Ä‘iá»ƒm sai hoáº·c nhá»¯ng gÃ¬ há»c sinh cÃ²n thiáº¿u.

Náº¿u lá»i giáº£i cá»§a há»c sinh Ä‘Ãºng, hÃ£y Ä‘Æ°a ra cÃ¡c bÆ°á»›c váº½ hÃ¬nh bá»• sung Ä‘á»ƒ minh há»a cho lá»i giáº£i nÃ y.

Tráº£ vá» JSON vá»›i Ä‘á»‹nh dáº¡ng:
{{
    "is_correct": true/false,
    "feedback": "Pháº£n há»“i chi tiáº¿t cho há»c sinh",
    "score": 0-100,
    "additional_illustration_steps": ["Váº½ Ä‘Æ°á»ng chÃ©o AB", "AB cáº¯t CD táº¡i E", ...] (chá»‰ khi is_correct = true vÃ  cÃ³ bÆ°á»›c váº½ hÃ¬nh bá»• sung. Náº¿u khÃ´ng thÃ¬ tráº£ vá» máº£ng rá»—ng)
}}
"""

    try:
        response = llm.invoke(validation_prompt)
        validation_data = safe_json_parse(
            response.content,
            {
                "is_correct": False,
                "feedback": "KhÃ´ng thá»ƒ Ä‘Ã¡nh giÃ¡ lá»i giáº£i",
                "score": 0,
                "additional_illustration_steps": [],
            },
        )

        state["is_validated"] = validation_data.get("is_correct", False)

        # Store validation feedback
        feedback = validation_data.get("feedback", "KhÃ´ng cÃ³ pháº£n há»“i")
        score = validation_data.get("score", 0)

        state["final_answer"] = (
            f"**Káº¿t quáº£ Ä‘Ã¡nh giÃ¡:**\n{feedback}\n\n**Äiá»ƒm: {score}/100**"
        )

        if state["is_validated"]:
            state["final_answer"] += "\n\nâœ… Lá»i giáº£i cá»§a báº¡n Ä‘Ã£ Ä‘Æ°á»£c cháº¥p nháº­n!"

            # MERGE AI discoveries into known facts when solution is validated
            ai_discoveries = state.get("ai_discovered_facts", [])
            current_known = state["known_facts"]

            # Add AI discoveries to known facts (avoid duplicates)
            for discovery in ai_discoveries:
                if discovery and discovery not in current_known:
                    current_known.append(discovery)

            state["known_facts"] = current_known
            # Clear AI discoveries since they're now part of known facts
            state["ai_discovered_facts"] = []

            # Add additional illustration steps when solution is validated
            additional_steps = validation_data.get("additional_illustration_steps", [])
            if additional_steps:
                state["illustration_steps"].extend(additional_steps)

    except Exception as e:
        state["final_answer"] = f"Lá»—i khi Ä‘Ã¡nh giÃ¡ lá»i giáº£i: {str(e)}"
        state["is_validated"] = False

    return state


def generate_solution(state: GraphState) -> GraphState:
    """
    Node 5: generate_solution
    Agent: "Solution Generation Agent"
    Transforms the structured reasoning into a formatted final answer.
    """
    llm = initialize_llm()
    if not llm:
        state["error_message"] = "KhÃ´ng thá»ƒ khá»Ÿi táº¡o mÃ´ hÃ¬nh AI."
        return state

    reasoning_chain = state["reasoning_chain"]
    current_question = state["questions"][state["current_question_index"]]

    solution_prompt = f"""
Báº¡n lÃ  má»™t giÃ¡o viÃªn hÃ¬nh há»c. HÃ£y viáº¿t má»™t lá»i giáº£i rÃµ rÃ ng, tá»«ng bÆ°á»›c dá»±a trÃªn chuá»—i logic sau.
Giáº£i thÃ­ch má»—i bÆ°á»›c má»™t cÃ¡ch rÃµ rÃ ng báº±ng tiáº¿ng Viá»‡t.

CÃ¢u há»i: {current_question}

Chuá»—i láº­p luáº­n:
{json.dumps(reasoning_chain, ensure_ascii=False, indent=2)}

HÃ£y viáº¿t lá»i giáº£i hoÃ n chá»‰nh vá»›i Ä‘á»‹nh dáº¡ng:
- Äáº§u tiÃªn nÃªu rÃµ Ä‘iá»u cáº§n chá»©ng minh/tÃ­nh toÃ¡n
- Tá»«ng bÆ°á»›c giáº£i thÃ­ch chi tiáº¿t
- Káº¿t luáº­n cuá»‘i cÃ¹ng

Sá»­ dá»¥ng Ä‘á»‹nh dáº¡ng Markdown Ä‘á»ƒ lÃ m Ä‘áº¹p lá»i giáº£i.
"""

    try:
        response = llm.invoke(solution_prompt)
        state["final_answer"] = response.content.strip()

        # Display the generated solution immediately
        print("\n" + "=" * 60)
        print("ðŸ“– Lá»œI GIáº¢I HOÃ€N CHá»ˆNH")
        print("=" * 60)
        print(state["final_answer"])
        print("=" * 60 + "\n")

        # MERGE AI discoveries into known facts when complete solution is provided
        ai_discoveries = state.get("ai_discovered_facts", [])
        current_known = state["known_facts"]

        # Add AI discoveries to known facts (avoid duplicates)
        for discovery in ai_discoveries:
            if discovery and discovery not in current_known:
                current_known.append(discovery)

        state["known_facts"] = current_known
        # Clear AI discoveries since they're now part of known facts
        state["ai_discovered_facts"] = []

    except Exception as e:
        state["final_answer"] = f"Lá»—i khi táº¡o lá»i giáº£i: {str(e)}"
        print(f"âŒ {state['final_answer']}")

    return state


def move_to_next_question(state: GraphState) -> GraphState:
    """
    Node 6: move_to_next_question
    Standard function to advance to the next question and reset interaction state.
    """
    # Increment question index
    state["current_question_index"] += 1

    # Reset interaction-specific state
    state["hint_level"] = 0
    state["generated_hints"] = []
    state["is_validated"] = False
    state["user_solution_attempt"] = ""
    state["final_answer"] = ""
    state["reasoning_chain"] = []
    state["ai_discovered_facts"] = []  # Reset AI discoveries for new question

    # Check if all questions are complete
    if state["current_question_index"] >= len(state["questions"]):
        state["session_complete"] = True
        completion_message = (
            "ðŸŽ‰ **ChÃºc má»«ng!** Báº¡n Ä‘Ã£ hoÃ n thÃ nh táº¥t cáº£ cÃ¢u há»i trong bÃ i toÃ¡n nÃ y!"
        )
        state["final_answer"] = completion_message

        # Display completion message immediately
        print("\n" + "=" * 60)
        print("ðŸŽ‰ HOÃ€N THÃ€NH BÃ€I TOÃN")
        print("=" * 60)
        print(completion_message)
        print("=" * 60 + "\n")

    # known_facts persists across questions
    return state


def await_user_action(state: GraphState) -> GraphState:
    """
    Active node that handles user input directly within the graph flow.
    Displays current question and prompts for user action.
    """

    def display_question_and_status(state: GraphState) -> None:
        """Display the current question and available user actions."""
        current_question_index = state.get("current_question_index", 0)
        questions = state.get("questions", [])

        if current_question_index >= len(questions):
            print("ðŸŽ‰ ÄÃ£ hoÃ n thÃ nh táº¥t cáº£ cÃ¢u há»i!")
            return

        current_question = questions[current_question_index]
        hint_level = state.get("hint_level", 0)
        generated_hints = state.get("generated_hints", [])

        print("=" * 60)
        print(f"ðŸ“‹ CÃ‚U Há»ŽI {current_question_index + 1}/{len(questions)}")
        print("=" * 60)
        print(f"â“ {current_question}")
        print()

        # Show current status - only user's known facts
        if state.get("known_facts"):
            print("ðŸ“ CÃ¡c sá»± kiá»‡n Ä‘Ã£ biáº¿t:")
            for i, fact in enumerate(state["known_facts"], 1):
                print(f"  {i}. {fact}")
            print()

        # Show hints if any have been generated
        if generated_hints:
            print("ðŸ’¡ Gá»£i Ã½ Ä‘Ã£ nháº­n:")
            for i, hint in enumerate(generated_hints, 1):
                print(f"\nðŸ“Œ Gá»£i Ã½ {i}:")
                print(f"  {hint}")
            print()

        # Show available actions
        print("ðŸŽ¯ CÃ¡c hÃ nh Ä‘á»™ng cÃ³ thá»ƒ thá»±c hiá»‡n:")
        print("  1. ðŸ’¡ Xin gá»£i Ã½ (hint)")
        print("  2. ðŸ“ Ná»™p lá»i giáº£i (submit)")
        print("  3. ðŸ“– Xem Ä‘Ã¡p Ã¡n (solution)")
        if state.get("is_validated"):
            print("  4. âž¡ï¸  CÃ¢u há»i tiáº¿p theo (next)")
        print("  5. ðŸ“Š Xem tráº¡ng thÃ¡i (status)")
        print("  6. ðŸšª ThoÃ¡t (exit)")
        print()

    def get_user_input_in_node() -> str:
        """Get user input for the current action within the graph node."""
        try:
            user_choice = input("ðŸ‘¤ Chá»n hÃ nh Ä‘á»™ng (1-6): ").strip()
            return user_choice
        except KeyboardInterrupt:
            print("\nðŸ‘‹ ThoÃ¡t chÆ°Æ¡ng trÃ¬nh...")
            return "6"  # Exit
        except Exception as e:
            print(f"âŒ Lá»—i: {e}")
            return ""

    current_question_index = state.get("current_question_index", 0)
    questions = state.get("questions", [])

    if current_question_index >= len(questions):
        state["session_complete"] = True
        return state

    # Display current question and status
    display_question_and_status(state)

    # Get user input directly
    user_choice = get_user_input_in_node()

    # Store user choice in state for routing
    state["user_action"] = user_choice

    return state
